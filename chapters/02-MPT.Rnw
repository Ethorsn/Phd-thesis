
Modern Portfolio Theory was introduced by \cite{markowitz1959portfolio}. 
In his seminal work he argued that any portfolio which simply maximize its profit will result in a naive solution.
Very much like the example in Chapter \ref{ch:intro}. 
The future is unknown and (one of) the best model(s) we have for it is stochastic.
Investing all your capital in the asset with the highest return is not sensible if you do not know the future.
Such an investment will cause you to take an extreme amount of risk. 
He therefore argued that any well diversified portfolio should be preferred to any non diversified portfolio. 
Such a portfolio can be obtained through many different procedures but he proposed the use of the first two moments for the allocation problem.
If an asset has high return on average, it might make sense to invest a lot in it although not at the cost of large amount of risk. If an asset is not risky, then it makes sense to invest in it.

We assume assets $\bx$ are random with mean $\optn{E}(\bx)=\bmu$ and covariance matrix $\optn{Var}(\bx)=\bSigma$. Although there is usually little restriction on $\bmu$ there is usually very specific restrictions on the covariance matrix $\bSigma$. Since the covariance matrix is a subject of its own we dedicate the next section to it and disregards these restrictions for now. We will merely say that it is well behaved. The restrictions on the mean will be commented on below. Using the two moments for the asset returns the portfolio distribution $x = \bw^\top \bx$ has mean $\optn{E}(x)=\bw^\top \bmu$ and variance $\optn{Var}(x)=\bw^\top \bSigma \bw$. Let $\mu_0$ be the target return that the investor would like to achieve from their portfolio and $\ones$ column vector of ones with appropriate dimensions. \citet{markowitz1959portfolio} considered the following optimization problem
\begin{equation}\label{eqn:markowitz_optim}
\begin{aligned}
& \underset{\bw}{\text{minimize}} 
& & \bw^\top \bSigma \bw \\
& \text{subject to}
& & \bw^\top \ones = 1 \\
& && \bw^\top \bmu \geq \mu_0 \\
&&& w_i \geq 0, i=1,2,..,p
\end{aligned}
\end{equation}
This problem is a quadratic optimization problem with linear equality and inequality constraints. 
The objective is to minimize the variance of the portfolio. 
%A natural question is to ask whether or not that implies diversification? As it turns out, minimizing the portfolio variance will encourage diversification from the fact that $$
%\textbf{Give example on using convex combinations on variances.} 
 The constraint $\bw^\top \ones = 1$ essentially states that the investor must invest all available money. 
The weights are scaled according to the amount of cash invested.
The disposition is very different whenever an inequality is used rather than equality. 
As \citet{hult2012risk} states, if $\bw^\top \ones \leq 1$, then the investor could be throwing money away since there is a lot of opportunity left in the market when investing.
The second constraint describes the investors expectations on the portfolio. 
As $\mu_0$ grows, the return of the portfolio will grow. 
However, that has implications for the objective. 
Increasing $\mu_0$ will change the amount of variance the portfolio can achieve. 
Depending on the value $\mu_0$ we would be accepting more risk. 
The last constraint is rather simple though have quite large implications. 
It states that the weights can not be negative which means that we can only invest money we have. 
A negative value of $w_i$ in the $i$th asset is called a short position.
You borrow the asset from someone who owns it and then sell it. 
Later on, you can buy it back, hoping that the price is less so that you can make money on such a position. 
For certain types of investors this constraint can be limiting and for others its a must.
In this thesis, we exclude it altogether. That is, this thesis considers
\begin{equation}\label{eqn:mean_variance}
\begin{aligned}
& \underset{\bw}{\text{minimize}} 
& & \bw^\top \bSigma \bw \\
& \text{subject to}
& & \bw^\top \ones = 1 \\
& && \bw^\top \bmu \geq \mu_0 \\
\end{aligned}
\end{equation}
which is what we refer to the mean-variance optimization problem. The solution to this problem is very often stated in terms of another famous portfolio, namely the Global Minimum Variance (GMV) portfolio and its related quantities (see e.g. \citet{Bodnar2009CaIotEFiEM, bodnar2013equivalence, bauder2018bayesian}). We will continue in the same manner. Let $\bSigma^{-1}$ denote the inverse matrix of $\bSigma$, e.g. $\bSigma^{-1}\bSigma = \bI$, and
\begin{equation}
	\bw_{GMV} := \frac{\bSigma^{-1}\ones}{\ones^\top \bSigma^{-1}\ones}, \; R_{GMV} :=\optn{E}(\bw_{GMV}^\top\bx) = \frac{\ones^\top\bSigma^{-1}\bmu}{\ones^\top \bSigma^{-1}\ones}, \;
	V_{GMV} := \optn{Var}(\bw_{GMV}^\top\bx) =\frac{1}{\ones^\top \bSigma^{-1}\ones}.
\end{equation}
The GMV portfolio can be obtained by letting $\mu_0=R_{GMV}$ or by removing the constraint $\bw^\top \bmu \geq \mu_0$. 
  
The solution to the mean-variance problem in \eqref{eqn:mean_variance} is equal to
\begin{equation}\label{eqn:mean_var_solution}
	\bw_{MV} = \frac{\bSigma^{-1}\ones}{\ones^\top \bSigma^{-1}\ones} + \frac{\mu_0 - R_{GMV}}{V_{GMV}} \bQ \bmu,\; \bQ = \bSigma^{-1} - \frac{\bSigma^{-1} \ones \ones^\top \bSigma^{-1}}{\ones^\top \bSigma^{-1} \ones}.
\end{equation}
\textbf{.....}

The moments of this portfolio is equal to
\begin{equation}\label{eqn:moments_mean_var_solution}
\optn{E}(\bw_{MV}^\top\bx) = R_{GMV} + \frac{\mu_0 - R_{GMV}}{V_{GMV}} \bmu^\top \bQ \bmu, \;
\optn{Var}(\bw_{MV}^\top\bx) =V_{GMV} + \left(\frac{\mu_0 - R_{GMV}}{V_{GMV}}\right)^2 \bmu^\top \bQ \bmu.
\end{equation}
If we set $\mu_0$ equal to $\bmu^\top \bSigma^{-1} \ones / \ones^\top \bSigma^{-1} \ones$ then the portfolio is equal to the GMV portfolio. 
Excluding the constraint $\bw^\top \bmu \geq \mu_0$ all together results in the same solution.
From equation \eqref{eqn:moments_mean_var_solution} we can see that all values $\mu_0$ are rescaled according to the moments of the GMV portfolio. 
If the taget return $\mu_0$ is not $\mu_0>R_{GMV}$ then you are better off with the GMV portfolio in terms of return and risk.
However, if you choose a value $\mu_0>R_{GMV}$ then the portfolio return will be more than $R_{GMV}$.

\textbf{Introduce merton and the efficient frontier and talk about $\bmu^\top \bQ \bmu$.}
<<mertons_efficient_frontier, fig.cap="Three different efficient frontiers for different portfolio sizes. The stocks are randomly selected from the S\\&P500. The individual means and std. are displayed as points in the background.">>=
set.seed(4)
df <-  select(HDShOP::SP_daily_asset_returns, -Date) %>%
  sample(30)

efficient_frontiers <- map_df(c(10,20,30), ~{
  df_tmp <- df[,1:.x]
  mu <- colMeans(df_tmp)
  Sigma_inv <- solve(var(df_tmp))
  ones <- as.vector(rep(1, length(mu)))
  
  Vgmv <- 1/as.numeric(t(ones)%*% Sigma_inv %*% ones)
  Rgmv <- t(mu)%*% Sigma_inv %*% ones / as.numeric(t(ones)%*% Sigma_inv %*% ones)
  Q <- Sigma_inv - Sigma_inv %*% ones %*% t(ones) %*% Sigma_inv / as.numeric(t(ones) %*% Sigma_inv %*% ones)
  s <- as.numeric(t(mu)%*% Q %*% mu)
  
  c("Vgmv"=Vgmv, "Rgmv"=Rgmv, "s"=s, "portfolio size"=.x)
  }) %>%
  mutate(`portfolio size`=as.character(`portfolio size`))

individual_assets <- tibble(
  "R"=colMeans(df),
  "V"=sqrt(diag(var(df)))
)

x <- 1:nrow(efficient_frontiers)
names(x) <- efficient_frontiers$`portfolio size`

ggplot_df <- map_dfr(x, ~{
  t_ <- efficient_frontiers[.x,]
  R <- seq(t_$Rgmv, 0.25, length.out=200)
  data.frame("V"=sqrt((R-t_$Rgmv)^2/t_$s + t_$Vgmv),
             "R"=R)
}, .id="portfolio size")

ggplot_df %>%
  ggplot() +
  geom_line(aes(x=V, y=R, 
                color=`portfolio size`,
                linetype=`portfolio size`),
            size=1.05) +
  geom_point(aes(x=sqrt(Vgmv), y=Rgmv, 
                 color=`portfolio size`), 
             size=2,
             alpha=0.7,
             data=efficient_frontiers) +
  geom_point(aes(x=V, y=R), data=individual_assets, alpha=0.2) +
  labs(x=expression(sigma[w]), y=expression(mu[w])) +
  theme_minimal() +
  theme(text = element_text(size=STANDARD_TEXT_SIZE),
        legend.position = "bottom")
@

\section{Relationship between assets and the (inverse) Covariance matrix}\label{subsec:cov_prec_matrix}
%%% ----------------------
The covariance matrix $\bSigma$ and the precision matrix $\bSigma^{-1}$ are fundemental to mean-variance portfolios. In this section we discuss the restrictions we place on the covariance matrix and what the precision matrix actually represent. 

For a vector $\bx$ with finite second moment, the covariance matrix is defined as $\bSigma=\optn{E}((\bx - \bmu)(\bx - \bmu)^\top)$. 
It contains the variances of each individual element of $\bx$ on the diagonal as well as the covariance between every pair of elements on the off-diagonal. 
That is, each diagonal element corresponds to the univariate case where the variance is equal to $\optn{E}((x_i - \mu_i)^2)$. 
In the univariate case, a distribution is usually called degenerate or singular if the variance is equal to zero. 
In the multivariate case. the covariance matrix can be singular on a number of occasions. 
It is not limited to the diagonal elements.    
This is due to the fact that we involve covariances on the off-diagonal and we are therefore forced to work with a broader definition.  
Since we work with real matrices in this thesis, we limit the definition accordingly. 
From \citet[ch 14.2]{harville1997matrix} we say that a real symmetric $p\times p$ matrix $\bA$ is called 
\begin{itemize}
	\item positive definite if $\bz^\top \bA \bz > 0$
	\item positive semi-definite if $\bz^\top \bA \bz \geq 0$
\end{itemize}
for all nonzero vectors $\bz \in \mathbbm{R}^p$.
In the multivariate case we need to assert that a quadratic form is (strictly) positive in comparison to the univariate setting where we can observe it through the variance. 
Positive- or semi-positive definite can be quite cumbersome to work with. 
We need to assert that the conditions holds for all vectors $\bz$. 
One necessary condition for a matrix to be positive definite can be derived using the eigenvalues of a matrix and its eigenvalue decomposition. 
As described in \citet[ch. 21]{harville1997matrix}, an eigenvalue (or characteristic root) $\lambda$ is the solution to 
\begin{definition}\label{def:eigenvalue} 
	Let $\bA$ be a $p\times p$ matrix. The characteristic roots (with multiplicity) are given by the solutions to
	\begin{equation*}
		\left|\bA - \lambda \bI\right| = 0
	\end{equation*}
	where $|\cdot|$ is the determinant of a matrix.
\end{definition} 
Let $\lambda_i$, $i=1,2,...,p$, denote the \textit{ordered} eigenvalues of the matrix $\bA$ such that $\lambda_1\geq \lambda_2 \geq ... \geq \lambda_p$.
Given an eigenvalue, the eigenvectors $\bu_i$ are defined by $\bA \bu_i = \lambda_i \bu_i$, $i=1,2,...,p$. 
Let $\boldsymbol{\Lambda} = \operatorname{diag}(\lambda_1, \lambda_2,...,\lambda_p)$ and $\bU= (\bu_1^\top, \bu_2^\top, ..., \bu_p^\top)^\top$. It might happen that some eigenvalues are equal, which implies that some eigenvectors have the same multiplicity.
Using the relation between eigenvalues and their eigenvectors we can derive the eigenvalue (or spectral) decomposition of a symmetric matrix 
\begin{equation}\label{eqn:eigenvalue_decomp}
	\bA = \bU \boldsymbol{\Lambda} \bU^{-1}.
\end{equation}
Since $\bA$ is symmetric it also holds that $\bU^{-1} = \bU^\top$.
A necessary condition for a matrix to be positive definite can be directly obtained from the eigenvalue decomposition. 
Let $\bz\in \mathbbm{R}^p$ and $\by := \bU^{\top} \bz \in \mathbbm{R}^p$, then $\bz^\top \bA \bz = \bz^\top \bU \boldsymbol{\Lambda} \bU ^{\top} \bz = \by^\top \boldsymbol{\Lambda} \by = \sum_i^p \lambda_i y_i^2$ which is a second degree polynomial. 
If the eigenvalues are all positive then necessarily the matrix is positive definite. 
If there are some eigenvalues which are zero then the matrix is semi-positive definite. 

In all papers of this thesis we assume that the true covariance matrix is positive definite. 
The assumption has quite a deep economical interpretation.
If one (or more) eigenvalue(s) are zero then there is a possibility to construct a portfolio which does not contain any risk with a potentially positive return. 
An opportunity which should not exist unless the elements of $\bmu$ are all zero.
Assume $\lambda_p=0$, let $\bu_p$ be its eigenvector and set $\bw = \bu_p / \sum_i^p u_{ip}$. 
The variance of that portfolio is zero since all eigenvectors are orthonormal and its mean is $\bw^\top \bmu$ which can be non-zero unless the elements of $\bmu$ are all zero.
If the true covariance matrix is not positive definite there might exist arbitrage opportunities, e.g. the possibility of making profit without taking any risk.

The eigenvalue decomposition is very useful.
First, it provides a simple way to construct inverses, which is very important for MPT as seen in \eqref{eqn:mean_var_solution}.
We claim that $\bB = \bU \boldsymbol{\Lambda}^{-1} \bU^{-1}$ is a valid inverse which is easy to verify since $\bB \bA = \bU \boldsymbol{\Lambda}^{-1} \bU^{-1} \bU \boldsymbol{\Lambda} \bU^{-1} = \bI$. 
To study the inverse we can study the inverse of the eigenvalues.
%Secondly, it contains a lot of information that might not be available at first glance. 
%If $\bA$ is a covariance matrix then it contains variances and covariances, describing relations between random variables. 
%The eigenvectors are rotations that try to capture as much variation as possible along its axis.
%The eigenvalues is the variation along the eigenvectors axis. 
%They describes how the system behaves and not the individual elements and their inverse values describe how the precision matrix behaves.