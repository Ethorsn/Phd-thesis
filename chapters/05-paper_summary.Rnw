The following papers are included in this thesis.
\section{Paper 1 - Sampling distributions of optimal portfolio weights and characteristics in small and large dimensions}\label{sec:paper1}
The paper investigates a fundamental question in MPT. 
What are the actual implications of using the sample covariance matrix $\bS$ and the sample mean $\byb$ instead of the true covariance matrix $\bSigma$ and mean vector $\bmu$?
The paper presents an answer to the question when the returns follow a multivariate normal distribution. 
It contains the distribution for all optimal portfolios on the common form
\begin{equation}\label{eqn:paper1_eq1}
  \bL\hbw_{opt} = \bL\hbw_{GMV} + g(\hR, \hV, \hs)\frac{\bL\hat{\bQ}\byb}{\hs}
\end{equation}
for some matrix $\bL$ of size $k \times p$ where $k<p$.
The joint distribution of all quantities in \eqref{eqn:paper1_eq1} is derived through a stochastic representation. 
The stochastic representation can be used to efficiently simulate from the distribution.
By simulation, quantities such as quantiles or other summary statistics are easily computed.
Furthermore, the high-dimensional asymptotic joint distribution is also derived. 
In a simulation study, the high-dimensional asymptotic distribution is compared to simulated data.
One scenario considers simulations from the stochastic representation, trying to deduce the finite-sample properties of the high-dimensional distribution.
The other scenarios try to investigate what happens when observations deviate from the model.
As expected, the high-dimensional distribution works well under the assumptions and seems to be reasonably robust from deviations of the model.
The GMV and self-financing portfolio are the most robust quantities to deviations from the model.

\section{Paper 2 - Tangency portfolio weights under a skew-normal model in small and large dimensions}\label{sec:paper2}
In this paper, the implications of skewness on the Tangency Portfolio (TP) from Chapter \ref{ch:MPT} is investigated. 
The portfolio is obtained from the quadratic utility function, namely
\begin{equation}
  \min_{\bw} \bw^\top (\bmu -r_f\ones) - \frac{\gamma}{2} \bw^\top \bSigma \bw.
\end{equation}
This paper extends paper 1 as it considers investments in a risk-free asset and use an extension of the multivariate normal model, the CSN model presented in Chapter \ref{ch:estim}. 
The model can include skewness in the asset returns, a trait returns usually exhibit (see e.g., \citet{cont2001empirical}). 
Similarly to paper 1, the distribution of the sample tangency portfolio is derived and the implications the skewness has on the portfolio.
In short, skewness results in a bias present in the portfolio weights. 
An investor will not hold the correct portfolio on average.
Furthermore, the high-dimensional distribution of the sample tangency portfolio is derived.
It can be seen that the skewness disappears asymptotically. 
The high-dimensional distribution is the same as previous research has shown (see, e.g., \citet{karlsson2021statistical}).

\section{Paper 3 - Dynamic shrinkage estimation of the high-dimensional minimum-variance portfolio}\label{sec:paper3}
This paper solves a practical feature when investing in the GMV portfolio: how to rebalance the portfolio at fixed time points. 
If an investor owns a GMV portfolio and waits for a week, month or year the data will likely indicate that another GMV portfolio should be held.
The change can be quite large if $n$ is sufficiently small.
A natural question to ask is how to go from one portfolio to another, e.g., how to rebalance optimally when a new set of data is available. 

In this paper, a dynamic rebalancing scheme for the GMV portfolio is derived. 
The scheme aims to decrease the out-of-sample variance between the holding portfolio, which might be a random GMV portfolio, and the GMV portfolio that is suggested by the current period's data. 
The portfolios are on the following form
\begin{equation}
  \hbw_{SH;n_{i}}=\psi_{i}\hbw_{S;n_i}+ (1-\psi_{i})\hbw_{SH;n_{i-1}},
\end{equation}
where $\hbw_{S;n_i}$, $i=1,2,...,T$, is the traditional sample GMV portfolio using the $i$th sample of size $n_i$ to estimate the GMV portfolio weights in \eqref{eqn:GMV}. 
The initial portfolio, $\hbw_{SH;0}$, can be a random GMV portfolio or a deterministic target portfolio $\bb$.
It is assumed that an investor has specified dates $t_i$, $i=1,2,...,T$ that he/she wants to rebalance his/her GMV portfolio. 
The shrinkage coefficients are then determined through the following optimization problem
$$
\min_{\psi_i} \hbw_{SH;n_{i}}^\top \bSigma \hbw_{SH;n_{i}}.
$$
The problem is similar to the linear shrinkage discussed in Chapter \ref{ch:highdim}.
The portfolio allocation problem is an extension to the work of \citet{bodnar2018estimation} and uses the flexible location and scale model in \eqref{eqn:location_scale_model}.

The portfolio is shown to produce great results in an extensive simulation study.
It also provides a better estimator for the volatility in comparison to the traditional sample GMV as well as the GMV portfolio using \citet{lw20} nonlinear shrinkage estimator for the sample covariance matrix.
There are also many other benefits of using the portfolio strategy.
Transitions from one portfolio to the next costs money, which will diminish the return and profit that can be made.
Furthermore, it is not always possible to go from one portfolio to the next in a day or even a month.
The traditional GMV portfolio might suggest that an institution should first own a large long position and the next month a large short position.
Depending on the size of the institution and the portfolio, the size of these positional changes might be illegal. 
It can be deemed market influencing or just outright impossible to sell that many assets.
The rebalancing scheme provides a solution to these problems.

\section{Paper 4 - Is the empirical out-of-sample variance an informative risk measure for high-dimensional portfolios?}\label{sec:paper4}
Any empirical application using the GMV portfolio is bound to include the volatility or variance as a performance measure. 
However, the empirical out-of-sample variance is not consistent.
Is the empirical out-of-sample variance for a shrunk portfolio a consistent estimator of the variance? 
Furthermore, is it a good option to use or are there perhaps better options to use as performance measures? 
This paper investigates two different metrics of evaluation that are common to the GMV portfolio, the out-of-sample variance and the relative out-of-sample loss.

This paper also considers the location and scale model from \eqref{eqn:location_scale_model} and three different GMV portfolios. 
The first portfolio is the traditional GMV portfolio from \eqref{eqn:GMV}, the second is the portfolio from \citet{bodnar2018estimation} and the last is the linear shrinkage portfolio from \citet{frahm2010}.
The properties of the out-of-sample variance, relative loss and their empirical counterparts are derived for the three different portfolios. 
It is done under different assumptions on the parameters of the model.
Most notably, there is a natural ordering to the different out-of-sample losses.
The empirical out-of-sample loss is smallest for \citet{bodnar2018estimation}, second to smallest is \citet{frahm2010} and the largest is the traditional sample GMV portfolio.
Furthermore, the empirical out-of-sample variance for the different portfolios are presented.
The assumptions that are necessary for convergence of the empirical out-of-sample variance are quite different from those used for the empirical out-of-sample loss.
The assumptions necessary for convergence of the empirical out-of-sample variance are deemed stronger than the empirical out-of-sample loss.
The theoretical findings are investigated in a simulation study and an empirical application which validate the ordering even when the model assumptions are violated.

\section{Paper 5 - Two is better than one: Regularized shrinkage of large
minimum variance portfolios}\label{sec:paper5}
The methods of this thesis most often use the sample covariance matrix $\bS$.
They deal with the fact that the sample covariance matrix is a noisy estimator for the portfolio weights by linear shrinkage on the weights themselves.
The estimator can only cover $c<1$.
This paper introduces a Thikonov regularization on the portfolio weights together with the linear shrinkage from prior papers. 
It results in a ridge type estimator for the sample covariance matrix together with the linear shrinkage on the portfolio weights.
There are two shrinkage types, one which put constraints on the sample covariance matrix and one which controls the weights.
This approach enables the method to cover the case where $c>1$ as well as let an investor input his/hers beliefs in the portfolio allocation problem.
The portfolio looks like
$$
\hbw_{SH} = \psi \frac{\left(\bS + \eta \bI_p \right)^{-1}\ones_p}{\ones_p^\top\left(\bS + \eta \bI_p \right)^{-1}\ones_p} + (1-\psi)\bb.
$$
The natural loss for estimating $\psi$ and $\eta$ is the out-of-sample variance.
It turns out it is not possible to construct a closed-form oracle estimator for the shrinkage parameters.
However, there is a possibility to construct an oracle loss function, for which a bona-fide estimator can be derived.
The bona-fide loss is proved to be a consistent estimator of the oracle loss.

The model is seen to perform on-par with the nonlinear shrinkage of \citet{lw20} in all simulations.
Further, the method consistently beats the \citet{lw20} method in an extensive empirical analysis.
The regularized shrinkage approach provides the best out-of-sample variance for five out of six different configurations.
Furthermore, the method also increases the performance of several other portfolio metrics.

%\section*{Paper 6 - The capital market line, tangency portfolio and the effect of Tikhonov regularization in higher dimensions}\label{sec:paper6}

\section{Other research results}\label{sec:other_results}

Paper 3 is accompanied by the DOSPortfolio R-package (see, \citet{DOSPortfolio}), available on CRAN. 
The readers of this thesis are free, or rather encouraged(!), to install it with \Sexpr{'install.packages("DOSPortfolio")'}. 
The package provides a simple interface for the methods implemented in the paper. 
In \ref{DOSportfolio} a short example on how to construct the dynamic portfolio weights using the package is displayed. 
The package is the first iteration of possibly many more portfolios which can be constructed in a similar fashion.
<<paper3-summary, echo=TRUE, message=FALSE, ref="DOSportfolio", codecap="R-code which showcase the use of the DOSPortfolio package." >>=
library(DOSPortfolio)
df <- read_csv("../data/returns.csv")
p <- 350; n <- 400
# Sample p assets
set.seed(1234)
asset_cols <- sample(2:ncol(df), size = p)
# specify reallocation points, daily in this case
reallocation_points <- seq(n, nrow(df), by=n)
# estimate portfolio weights
dos_weights <- df %>%
  select(all_of(asset_cols), -date) %>%
  DOSPortfolio(reallocation_points = reallocation_points,
               target_portfolio = rep(1, ncol(.))/ncol(.),
               shrinkage_type = "overlapping")
@
Furthermore, the following papers were co-authored throughout the writing of this thesis: \cite{bodnar2020quantile}, \cite{bodnar2021bayesian}  and \cite{bodnar2021quantile}.
The first presents an analytic derivation of the MPT framework in the Bayesian setting. 
It specifically investigates how quantiles of optimal portfolios can be constructed and the effects of estimation uncertainty in these. 
This is especially important since the regulations in place demands that quantile-based risk measures are reported (see \citet{basel4}).
The second paper provides a continuation on the first. 
The idea is to model the belief of an investor in a prior distribution. 
The method then aims to construct the prior distribution to capture what the likelihood cannot. 
It imposes a prior distribution which adapts to the recent observations when the market is turbulent. 
The algorithm is seen to work well when markets are turbulent.
The third paper also considers quantile-based portfolios. 
The paper does so in a general framework, not necessarily the same framework as MPT where the first two moments of the return distribution are used.

<<examplePackage, fig.cap="Development of wealth using the weights from the DOSPortfolio package together with the traditional GMV portfolio estimator. In this scenario, the portfolio size is equal to 380 and the number of data points in each window is equal to 400. Dashed vertical lines indicate a reallocation point.", eval=FALSE>>=
df <- select(df, date, all_of(asset_cols))
rec <- c(1,reallocation_points, nrow(df))
ggplot_df1 <- map_dfr(1:(length(rec)-2), ~{
      insample_data <- df[(rec[.x]):rec[.x+1], -1]
      future_returns <- t(as.matrix(df[(rec[.x+1]+1):rec[.x+2], -1]))
      
      S <- var(insample_data)
      S_inv <- solve(S)
      ones <- rep(1, nrow(S_inv))
      
      weights <- S_inv %*% ones / as.numeric(t(ones)%*% S_inv %*% ones)
      data.frame(
        "value"=c(t(weights) %*% future_returns)
      )
    }) %>%
  mutate(date=df$date[(reallocation_points[1]+1):nrow(df)],
         type="Traditional GMV")

rec <- c(reallocation_points, nrow(df))
ggplot_df <- map_dfr(1:(length(rec)-1), ~{
  future_returns <- t(as.matrix(df[(rec[.x]+1):rec[.x+1], -1]))
  data.frame(
    "value"=c(t(dos_weights$weights[.x,]) %*% future_returns)
  )
}) %>%
  mutate(date=df$date[(reallocation_points[1]+1):nrow(df)],
         type="DOSPortfolio") %>%
  bind_rows(ggplot_df1) %>%
  group_by(type) %>%
  arrange(date) %>%
  mutate(wealth=cumprod(1+value))

ggplot(ggplot_df) +
  geom_line(aes(x=date, y=wealth, color=type)) +
  geom_vline(xintercept = df$date[reallocation_points], alpha=0.5, linetype=2) +
  theme_minimal() +
  scale_color_brewer("", palette = 6, type = "qual") +
  scale_linetype("") +
  theme(text = element_text(size=STANDARD_TEXT_SIZE),
        legend.position = "bottom")
@